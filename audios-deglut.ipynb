{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este trabalho utiliza o DeepUai, um módulo original criado para facilitar operações de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _imports_ & HELLO WORLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3LL0 W0RLD\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "from models import DeepUaiDataset\n",
    "DeepUaiDataset.hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de Dados Disponíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets disponíveis:\n",
      " ['deglut-audios-wav', 'deglut-audios-statistics2']\n"
     ]
    }
   ],
   "source": [
    "print('Datasets disponíveis:\\n', DeepUaiDataset.available_datasets())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos disponíveis os datasets de áudios de deglutição e a versão de estatísticas desses mesmos áudios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é utilizar um Detector de Anomalias para filtrar os áudios válidos dos inválidos.\n",
    "\n",
    "O DeepUai permitirá criar facilmente um novo **conjunto de dados** apenas com os dados válidos. Será preciso utilizar esse **conjunto de dados** gerado para filtrar os arquivos de áudio válidos, uma vez que o **conjunto de dados** gerado é apenas das estatísticas, e pretendemos aplicar outros modelos de Machine Learning nos áudios válidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE [200]\n",
      "[UPDATE: 200]\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from models.mlns.outlier import DeepUaiOutlierDetection\n",
    "\n",
    "clf = IsolationForest(contamination=.5)\n",
    "deepuai = DeepUaiOutlierDetection(clf=clf, name='iforest-standand',\n",
    "                                  ds_name='deglut-audios-statistics2')\n",
    "y = deepuai.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deglut-audios-statistics2-inliers, 245 itens, 0.03344154357910156 MB\n",
      "deglut-audios-wav, 490 itens, 955.6767692565918 MB\n",
      "deglut-audios-wav-inliers, 245 itens, 506.48830795288086 MB\n"
     ]
    }
   ],
   "source": [
    "stats_inliers_ds = deepuai.create_inliers_ds()\n",
    "print(stats_inliers_ds)\n",
    "\n",
    "wav_ds = DeepUaiDataset('deglut-audios-wav')\n",
    "print(wav_ds)\n",
    "\n",
    "inliers_fnames = [os.path.basename(fpath).split('.')[0]\n",
    "                  for fpath in stats_inliers_ds.filepaths]\n",
    "\n",
    "wav_inliers_ds_name = 'deglut-audios-wav-inliers'\n",
    "wav_inliers_ds_path = DeepUaiDataset._get_path(wav_inliers_ds_name)\n",
    "if not os.path.exists(wav_inliers_ds_path): os.makedirs(wav_inliers_ds_path)\n",
    "\n",
    "for fpath in wav_ds.filepaths:\n",
    "    basename = os.path.basename(fpath)\n",
    "    fname = basename.split('.')[0]\n",
    "    if fname in inliers_fnames:\n",
    "        shutil.copyfile(fpath, os.path.join(wav_inliers_ds_path, basename))\n",
    "wav_inliers_ds = DeepUaiDataset(wav_inliers_ds_name)\n",
    "print(wav_inliers_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo os Inliers em Janelas de Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def get_rate(ds: DeepUaiDataset):\n",
    "    fname, _ = next(ds.samples(fnames=True))\n",
    "    wavfilepath = os.path.join(ds.path, fname)\n",
    "    rate, _ = wavfile.read(wavfilepath)\n",
    "    return rate\n",
    "\n",
    "def wav2json_windows(ds: DeepUaiDataset, window_duration = 5): # seconds\n",
    "    new_ds_name = f'{ds.name}-{window_duration}s'\n",
    "    new_ds_path = DeepUaiDataset._get_path(new_ds_name)\n",
    "    if not os.path.exists(new_ds_path): os.makedirs(new_ds_path)\n",
    "    \n",
    "    rate = get_rate(ds)\n",
    "    window_size = int(rate * window_duration)\n",
    "    step_size = window_size // 2\n",
    "    for fname, sample in ds.samples(fnames=True):\n",
    "        fname = fname.split('.')[0]\n",
    "        i, start, stop = 0, 0, step_size\n",
    "        while stop < len(sample):\n",
    "            with open(os.path.join(new_ds_path, f'{fname}-{i}.json'), 'w') as file:\n",
    "                json.dump(sample[start:stop].tolist(), file)\n",
    "            i += 1\n",
    "            start += step_size\n",
    "            stop += step_size\n",
    "    new_ds = DeepUaiDataset(name=new_ds_name)\n",
    "    return new_ds\n",
    "\n",
    "inliers_ds_name = 'deglut-audios-wav-inliers'\n",
    "inliers_ds = DeepUaiDataset(inliers_ds_name)\n",
    "windowed_inliers_ds = wav2json_windows(ds=inliers_ds)\n",
    "windowed_inliers_ds_name = windowed_inliers_ds.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificando Janelas de Tempo com Detecção de Anomalias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraindo informações das Janelas de Tempo\n",
    "\n",
    "As janelas de tempo possuem 110 mil amostras, o que torna impraticável a aplicação da floresta isolada nos dados crus. Será aplicada a mesma transformação utilizada na primeira detecção de anomalias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deglut-audios-wav-inliers-5s-statistics2, 2293 itens, 0.20721149444580078 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_statistics2(y: list):\n",
    "    y = np.asarray(y)\n",
    "    mean = np.mean(y)\n",
    "    std_dev = np.std(y)\n",
    "    min_val = np.min(y)\n",
    "    max_val = np.max(y)\n",
    "    median = np.median(y)\n",
    "    q1 = np.percentile(y, 25)\n",
    "    q3 = np.percentile(y, 75)\n",
    "    energy = np.sum(y ** 2)\n",
    "    statistics = {'Mean': mean, 'Standard Deviation': std_dev,\n",
    "                  'Minimum': min_val, 'Maximum': max_val,\n",
    "                  'Median': median, 'Q1': q1, 'Q3': q3, 'Energy': energy}\n",
    "    return [float(s) for s in statistics.values()]\n",
    "\n",
    "windowed_inliers_ds_name = 'deglut-audios-wav-inliers-5s'\n",
    "windowed_inliers_ds = DeepUaiDataset(windowed_inliers_ds_name)\n",
    "\n",
    "windows_stats_ds_name = windowed_inliers_ds_name + f'-statistics2'\n",
    "windows_stats_ds_path = DeepUaiDataset._get_path(windows_stats_ds_name)\n",
    "if not os.path.exists(windows_stats_ds_path): os.makedirs(windows_stats_ds_path)\n",
    "for fname, window in windowed_inliers_ds.samples(fnames=True):\n",
    "    with open(os.path.join(windows_stats_ds_path, fname), 'w') as file:\n",
    "        json.dump(compute_statistics2(window), file)\n",
    "windows_stats_ds = DeepUaiDataset(windows_stats_ds_name)\n",
    "print(windows_stats_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificando as Janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE [200]\n",
      "[UPDATE: 200]\n",
      "deglut-audios-wav-inliers-5s-statistics2-classified, 2293 itens, 0.20721149444580078 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from models.mlns.outlier import DeepUaiOutlierDetection\n",
    "\n",
    "clf = IsolationForest(n_estimators=4)\n",
    "deepuai = DeepUaiOutlierDetection(clf=clf, name='iforest-windows',\n",
    "                                  ds_name=windows_stats_ds.name)\n",
    "y = deepuai.execute()\n",
    "classified_windows_ds = deepuai.create_classified_ds()\n",
    "print(classified_windows_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando DeepLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia aqui é utilizar a classificação com Detecção de Anomalias como se fosse uma classificação feita por um especialista e aplicar um classificador com DeepLearning sob as janelas classificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 23:04:19.617599: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-06 23:04:19.618220: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 23:04:19.621503: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 23:04:19.667946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 23:04:20.713006: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: 8\n",
      "(array([0, 1]), array([ 693, 1600]))\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuxinha/code/deepuai/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5816 - loss: 0.6838 - val_accuracy: 1.0000 - val_loss: 0.4879\n",
      "Epoch 2/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6256 - loss: 0.6555 - val_accuracy: 0.9599 - val_loss: 0.5291\n",
      "Epoch 3/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6683 - loss: 0.6371 - val_accuracy: 0.9495 - val_loss: 0.4666\n",
      "Epoch 4/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6570 - loss: 0.6285 - val_accuracy: 0.9408 - val_loss: 0.4618\n",
      "Epoch 5/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6413 - loss: 0.6301 - val_accuracy: 0.9477 - val_loss: 0.4285\n",
      "Epoch 6/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.6137 - val_accuracy: 0.9495 - val_loss: 0.4352\n",
      "Epoch 7/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6702 - loss: 0.6142 - val_accuracy: 0.9408 - val_loss: 0.4730\n",
      "Epoch 8/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6751 - loss: 0.6144 - val_accuracy: 0.9460 - val_loss: 0.4346\n",
      "Epoch 9/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6787 - loss: 0.6034 - val_accuracy: 0.9268 - val_loss: 0.4877\n",
      "Epoch 10/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6786 - loss: 0.6066 - val_accuracy: 0.9495 - val_loss: 0.4419\n",
      "Epoch 11/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.5925 - val_accuracy: 0.9791 - val_loss: 0.3342\n",
      "Epoch 12/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.5840 - val_accuracy: 0.8780 - val_loss: 0.4862\n",
      "Epoch 13/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.5836 - val_accuracy: 0.9582 - val_loss: 0.4102\n",
      "Epoch 14/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7166 - loss: 0.5681 - val_accuracy: 0.7944 - val_loss: 0.5104\n",
      "Epoch 15/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.5837 - val_accuracy: 0.9355 - val_loss: 0.4410\n",
      "Epoch 16/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7051 - loss: 0.5676 - val_accuracy: 0.9303 - val_loss: 0.4371\n",
      "Epoch 17/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.5621 - val_accuracy: 0.9669 - val_loss: 0.3719\n",
      "Epoch 18/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7003 - loss: 0.5837 - val_accuracy: 0.9686 - val_loss: 0.3514\n",
      "Epoch 19/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7086 - loss: 0.5621 - val_accuracy: 0.9599 - val_loss: 0.3749\n",
      "Epoch 20/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7138 - loss: 0.5674 - val_accuracy: 0.7003 - val_loss: 0.5925\n",
      "Epoch 21/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.5791 - val_accuracy: 0.9826 - val_loss: 0.2801\n",
      "Epoch 22/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6844 - loss: 0.5875 - val_accuracy: 0.8885 - val_loss: 0.4331\n",
      "Epoch 23/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.5509 - val_accuracy: 0.7805 - val_loss: 0.5224\n",
      "Epoch 24/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7087 - loss: 0.5756 - val_accuracy: 0.8432 - val_loss: 0.4630\n",
      "Epoch 25/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5403 - val_accuracy: 0.8484 - val_loss: 0.4947\n",
      "Epoch 26/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7078 - loss: 0.5646 - val_accuracy: 0.9146 - val_loss: 0.4190\n",
      "Epoch 27/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7247 - loss: 0.5536 - val_accuracy: 0.9582 - val_loss: 0.3760\n",
      "Epoch 28/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7234 - loss: 0.5512 - val_accuracy: 0.9686 - val_loss: 0.3234\n",
      "Epoch 29/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7135 - loss: 0.5707 - val_accuracy: 0.9512 - val_loss: 0.3548\n",
      "Epoch 30/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7506 - loss: 0.5283 - val_accuracy: 0.8850 - val_loss: 0.4285\n",
      "Epoch 31/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.5393 - val_accuracy: 0.9617 - val_loss: 0.3663\n",
      "Epoch 32/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7570 - loss: 0.5321 - val_accuracy: 0.9530 - val_loss: 0.3683\n",
      "Epoch 33/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.5236 - val_accuracy: 0.9739 - val_loss: 0.2886\n",
      "Epoch 34/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.5589 - val_accuracy: 0.9042 - val_loss: 0.4101\n",
      "Epoch 35/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7518 - loss: 0.5220 - val_accuracy: 0.9251 - val_loss: 0.3358\n",
      "Epoch 36/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5444 - val_accuracy: 0.9094 - val_loss: 0.4005\n",
      "Epoch 37/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5347 - val_accuracy: 0.8815 - val_loss: 0.4257\n",
      "Epoch 38/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7461 - loss: 0.5191 - val_accuracy: 0.8868 - val_loss: 0.4189\n",
      "Epoch 39/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7430 - loss: 0.5228 - val_accuracy: 0.9146 - val_loss: 0.3738\n",
      "Epoch 40/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7560 - loss: 0.5166 - val_accuracy: 0.9129 - val_loss: 0.3703\n",
      "Epoch 41/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7561 - loss: 0.5094 - val_accuracy: 0.8415 - val_loss: 0.4815\n",
      "Epoch 42/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.5395 - val_accuracy: 0.9547 - val_loss: 0.3485\n",
      "Epoch 43/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.5303 - val_accuracy: 0.9321 - val_loss: 0.3736\n",
      "Epoch 44/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7516 - loss: 0.5206 - val_accuracy: 0.9111 - val_loss: 0.3607\n",
      "Epoch 45/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7539 - loss: 0.5217 - val_accuracy: 0.8554 - val_loss: 0.4538\n",
      "Epoch 46/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7532 - loss: 0.5174 - val_accuracy: 0.9443 - val_loss: 0.3043\n",
      "Epoch 47/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7683 - loss: 0.5138 - val_accuracy: 0.9146 - val_loss: 0.3857\n",
      "Epoch 48/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7528 - loss: 0.5267 - val_accuracy: 0.9355 - val_loss: 0.3409\n",
      "Epoch 49/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5111 - val_accuracy: 0.8415 - val_loss: 0.4660\n",
      "Epoch 50/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.5193 - val_accuracy: 0.8537 - val_loss: 0.4507\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.8345 - loss: 0.4564\n",
      "Loss: 0.4507151246070862, Accuracy: 0.8536585569381714\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "ds = classified_windows_ds\n",
    "train_part = .75\n",
    "x, y = ds.classified_samples()\n",
    "x, y = np.asarray(list(x)), np.asarray(list(y))\n",
    "x = normalize(x, axis=0)\n",
    "limit = int(len(x) * train_part)\n",
    "X_train, y_train = x[:limit], y[:limit]\n",
    "X_test, y_test = x[limit:], y[limit:]\n",
    "print('shape:', X_train.shape[1])\n",
    "classes = np.unique(y, return_counts=True)\n",
    "print(classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # For binary classification, use sigmoid activation\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), shuffle=True)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deu para obter uma acurácia legal depois de normalizar o conjunto de dados e quebrar um pouco a cabeça com manipulação de arquivos para conseguir deixar o pacote _cross plataform_.\n",
    "\n",
    "O próximo passo do DeepUAI é o treinamento distribuido, ou seja, fazer as pré-configurações na máquina local e rodar os treinamentos a partir de uma instância remota.\n",
    "\n",
    "É possível encontrar o DeepUAI neste repositório: https://github.com/fabiorx1/deepuai3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
